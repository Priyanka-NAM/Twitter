{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e6c983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: pipenv: command not found\n",
      "/bin/bash: pipenv: command not found\n",
      "/bin/bash: pipenv: command not found\n",
      "/bin/bash: pipenv: command not found\n",
      "/bin/bash: pipenv: command not found\n"
     ]
    }
   ],
   "source": [
    "!pipenv install pandas\n",
    "!pipenv install numpy\n",
    "!pipenv install matplotlib\n",
    "!pipenv install sklearn\n",
    "!pipenv install wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3663a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec925b3e",
   "metadata": {},
   "source": [
    "Data for classification http://ama.liglab.fr/data/buzz/classification/Twitter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8bb068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Twitter_Absolute_Sigma = pd.read_table('Twitter-Absolute-Sigma-500.data',sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6303f68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>889</th>\n",
       "      <th>939</th>\n",
       "      <th>960</th>\n",
       "      <th>805</th>\n",
       "      <th>805.1</th>\n",
       "      <th>1143</th>\n",
       "      <th>1121</th>\n",
       "      <th>549</th>\n",
       "      <th>613</th>\n",
       "      <th>587</th>\n",
       "      <th>...</th>\n",
       "      <th>1.000000.26</th>\n",
       "      <th>1.000000.27</th>\n",
       "      <th>889.2</th>\n",
       "      <th>939.2</th>\n",
       "      <th>960.2</th>\n",
       "      <th>805.4</th>\n",
       "      <th>805.5</th>\n",
       "      <th>1143.2</th>\n",
       "      <th>1121.2</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>542</td>\n",
       "      <td>473</td>\n",
       "      <td>504</td>\n",
       "      <td>626</td>\n",
       "      <td>647</td>\n",
       "      <td>795</td>\n",
       "      <td>832</td>\n",
       "      <td>366</td>\n",
       "      <td>288</td>\n",
       "      <td>318</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>542</td>\n",
       "      <td>473</td>\n",
       "      <td>504</td>\n",
       "      <td>626</td>\n",
       "      <td>647</td>\n",
       "      <td>795</td>\n",
       "      <td>832</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>196</td>\n",
       "      <td>100</td>\n",
       "      <td>184</td>\n",
       "      <td>79</td>\n",
       "      <td>162</td>\n",
       "      <td>66</td>\n",
       "      <td>59</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>196</td>\n",
       "      <td>100</td>\n",
       "      <td>184</td>\n",
       "      <td>79</td>\n",
       "      <td>162</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "      <td>344</td>\n",
       "      <td>184</td>\n",
       "      <td>848</td>\n",
       "      <td>184</td>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "      <td>344</td>\n",
       "      <td>184</td>\n",
       "      <td>848</td>\n",
       "      <td>184</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169</td>\n",
       "      <td>98</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>185</td>\n",
       "      <td>141</td>\n",
       "      <td>68</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>169</td>\n",
       "      <td>98</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>185</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>775</td>\n",
       "      <td>765</td>\n",
       "      <td>935</td>\n",
       "      <td>806</td>\n",
       "      <td>912</td>\n",
       "      <td>1095</td>\n",
       "      <td>1198</td>\n",
       "      <td>614</td>\n",
       "      <td>588</td>\n",
       "      <td>751</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>775</td>\n",
       "      <td>765</td>\n",
       "      <td>935</td>\n",
       "      <td>806</td>\n",
       "      <td>912</td>\n",
       "      <td>1095</td>\n",
       "      <td>1198</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140701</th>\n",
       "      <td>1700</td>\n",
       "      <td>1386</td>\n",
       "      <td>1364</td>\n",
       "      <td>1437</td>\n",
       "      <td>1627</td>\n",
       "      <td>2040</td>\n",
       "      <td>1736</td>\n",
       "      <td>697</td>\n",
       "      <td>579</td>\n",
       "      <td>501</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1700</td>\n",
       "      <td>1386</td>\n",
       "      <td>1364</td>\n",
       "      <td>1437</td>\n",
       "      <td>1627</td>\n",
       "      <td>2040</td>\n",
       "      <td>1736</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140702</th>\n",
       "      <td>1280</td>\n",
       "      <td>1725</td>\n",
       "      <td>758</td>\n",
       "      <td>66</td>\n",
       "      <td>1254</td>\n",
       "      <td>1146</td>\n",
       "      <td>1353</td>\n",
       "      <td>493</td>\n",
       "      <td>527</td>\n",
       "      <td>293</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211255</td>\n",
       "      <td>1.197940</td>\n",
       "      <td>1287</td>\n",
       "      <td>1735</td>\n",
       "      <td>759</td>\n",
       "      <td>67</td>\n",
       "      <td>1257</td>\n",
       "      <td>1155</td>\n",
       "      <td>1359</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140703</th>\n",
       "      <td>1128</td>\n",
       "      <td>1190</td>\n",
       "      <td>1273</td>\n",
       "      <td>1250</td>\n",
       "      <td>1302</td>\n",
       "      <td>1575</td>\n",
       "      <td>1490</td>\n",
       "      <td>403</td>\n",
       "      <td>480</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>1.174242</td>\n",
       "      <td>1.207610</td>\n",
       "      <td>1135</td>\n",
       "      <td>1200</td>\n",
       "      <td>1284</td>\n",
       "      <td>1256</td>\n",
       "      <td>1316</td>\n",
       "      <td>1584</td>\n",
       "      <td>1498</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140704</th>\n",
       "      <td>1228</td>\n",
       "      <td>1343</td>\n",
       "      <td>1999</td>\n",
       "      <td>1789</td>\n",
       "      <td>1643</td>\n",
       "      <td>1626</td>\n",
       "      <td>2582</td>\n",
       "      <td>487</td>\n",
       "      <td>506</td>\n",
       "      <td>752</td>\n",
       "      <td>...</td>\n",
       "      <td>1.185776</td>\n",
       "      <td>1.217879</td>\n",
       "      <td>1240</td>\n",
       "      <td>1352</td>\n",
       "      <td>2006</td>\n",
       "      <td>1797</td>\n",
       "      <td>1651</td>\n",
       "      <td>1631</td>\n",
       "      <td>2584</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140705</th>\n",
       "      <td>1689</td>\n",
       "      <td>1468</td>\n",
       "      <td>0</td>\n",
       "      <td>1721</td>\n",
       "      <td>1699</td>\n",
       "      <td>1565</td>\n",
       "      <td>1688</td>\n",
       "      <td>618</td>\n",
       "      <td>610</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.129936</td>\n",
       "      <td>1.100945</td>\n",
       "      <td>1702</td>\n",
       "      <td>1478</td>\n",
       "      <td>0</td>\n",
       "      <td>1722</td>\n",
       "      <td>1702</td>\n",
       "      <td>1570</td>\n",
       "      <td>1694</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140706 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         889   939   960   805  805.1  1143  1121  549  613  587  ...  \\\n",
       "0        542   473   504   626    647   795   832  366  288  318  ...   \n",
       "1         92    99   196   100    184    79   162   66   59  118  ...   \n",
       "2         90    87    92   344    184   848   184   83   78   76  ...   \n",
       "3        169    98   101    90     96    95   185  141   68   85  ...   \n",
       "4        775   765   935   806    912  1095  1198  614  588  751  ...   \n",
       "...      ...   ...   ...   ...    ...   ...   ...  ...  ...  ...  ...   \n",
       "140701  1700  1386  1364  1437   1627  2040  1736  697  579  501  ...   \n",
       "140702  1280  1725   758    66   1254  1146  1353  493  527  293  ...   \n",
       "140703  1128  1190  1273  1250   1302  1575  1490  403  480  486  ...   \n",
       "140704  1228  1343  1999  1789   1643  1626  2582  487  506  752  ...   \n",
       "140705  1689  1468     0  1721   1699  1565  1688  618  610    0  ...   \n",
       "\n",
       "        1.000000.26  1.000000.27  889.2  939.2  960.2  805.4  805.5  1143.2  \\\n",
       "0          1.000000     1.000000    542    473    504    626    647     795   \n",
       "1          1.000000     1.000000     92     99    196    100    184      79   \n",
       "2          1.000000     1.000000     90     87     92    344    184     848   \n",
       "3          1.000000     1.000000    169     98    101     90     96      95   \n",
       "4          1.000000     1.000000    775    765    935    806    912    1095   \n",
       "...             ...          ...    ...    ...    ...    ...    ...     ...   \n",
       "140701     1.000490     1.000000   1700   1386   1364   1437   1627    2040   \n",
       "140702     1.211255     1.197940   1287   1735    759     67   1257    1155   \n",
       "140703     1.174242     1.207610   1135   1200   1284   1256   1316    1584   \n",
       "140704     1.185776     1.217879   1240   1352   2006   1797   1651    1631   \n",
       "140705     1.129936     1.100945   1702   1478      0   1722   1702    1570   \n",
       "\n",
       "        1121.2  1.0  \n",
       "0          832  1.0  \n",
       "1          162  0.0  \n",
       "2          184  1.0  \n",
       "3          185  1.0  \n",
       "4         1198  1.0  \n",
       "...        ...  ...  \n",
       "140701    1736  1.0  \n",
       "140702    1359  1.0  \n",
       "140703    1498  1.0  \n",
       "140704    2584  1.0  \n",
       "140705    1694  1.0  \n",
       "\n",
       "[140706 rows x 78 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Twitter_Absolute_Sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ebf72",
   "metadata": {},
   "source": [
    "# The data dosen't have column names.\n",
    "Giving coloumn names based on data here http://ama.liglab.fr/data/buzz/classification/Twitter/Absolute_labeling/Twitter-Absolute-Sigma-500.names\n",
    "\n",
    "Attributes explanation:\n",
    "\n",
    "1. **Columns [0  -  6]** => Number of Created Discussions (NCD)\n",
    "    <br /> This feature measures the number of discussions created at time step t and involving the instance's topic.<br /><br />\n",
    "2. **Columns [7  - 13]** => Author Increase (AI)\n",
    "    <br />This featurethe number of new authors interacting on the instance's topic at time t (i.e. its popularity)<br /><br />\n",
    "3. **Columns [14 - 20]** => Attention Level (measured with number of authors) (AS(NA))\n",
    "    <br />This feature is a measure of the attention payed to a the instance's topic on a social media.<br /><br />\n",
    "4. **Columns [21 - 27]** => Burstiness Level (BL)\n",
    "    <br />The burstiness level for a topic z at a time t is defined as the ratio of ncd and nad<br /><br />\n",
    "5. **Columns [28 - 34]** => Number of Atomic Containers (NAC)\n",
    "    <br />This feature measures the total number of atomic containers generated through the whole social media on the instance's topic until time t.<br /><br />\n",
    "6. **Columns [35 - 41]** => Attention Level (measured with number of contributions) (AS(NAC))\n",
    "    <br />This feature is a measure of the attention payed to a the instance's topic on a social media.<br /><br />\n",
    "7. **Columns [42 - 48]** => Contribution Sparseness (CS)\n",
    "    <br />This feature is a measure of spreading of contributions over discussion for the instance's topic at time t.<br /><br />\n",
    "8. **Columns [49 - 55]** => Author Interaction (AT)\n",
    "    <br />This feature measures the average number of authors interacting on the instance's topic within a discussion.<br /><br />\n",
    "9. **Columns [56 - 62]** => Number of Authors (NA)\n",
    "    <br />This feature measures the number of authors interacting on the instance's topic at time t.<br /><br />\n",
    "10. **Columns [63 - 69]** => Average Discussions Length (ADL)\n",
    "    <br />This feature directly measures the average length of a discussion belonging to the instance's topic.<br /><br />\n",
    "11. **Columns [70 - 76]** => Average Discussions Length (NAD)\n",
    "    <br />This features measures the number of discussions involving the instance's topic until time t.<br /><br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffb4632",
   "metadata": {},
   "outputs": [],
   "source": [
    "Twitter_Absolute_Sigma.columns= [\"NCD_0\", \"NCD_1\", \"NCD_2\", \"NCD_3\", \"NCD_4\", \"NCD_5\", \"NCD_6\", \"AI_0\", \"AI_1\", \"AI_2\", \"AI_3\", \"AI_4\", \"AI_5\", \"AI_6\", \"AS_NA_0\", \"AS_NA_1\", \"AS_NA_2\", \"AS_NA_3\", \"AS_NA_4\", \"AS_NA_5\", \"AS_NA_6\", \"BL_0\", \"BL_1\", \"BL_2\", \"BL_3\", \"BL_4\", \"BL_5\", \"BL_6\", \"NAC_0\", \"NAC_1\", \"NAC_2\", \"NAC_3\", \"NAC_4\", \"NAC_5\", \"NAC_6\", \"AS_NAC_0\", \"AS_NAC_1\", \"AS_NAC_2\", \"AS_NAC_3\", \"AS_NAC_4\", \"AS_NAC_5\", \"AS_NAC_6\", \"CS_0\", \"CS_1\", \"CS_2\", \"CS_3\", \"CS_4\", \"CS_5\", \"CS_6\", \"AT_0\", \"AT_1\", \"AT_2\", \"AT_3\", \"AT_4\", \"AT_5\", \"AT_6\", \"NA_0\", \"NA_1\", \"NA_2\", \"NA_3\", \"NA_4\", \"NA_5\", \"NA_6\", \"ADL_0\", \"ADL_1\", \"ADL_2\", \"ADL_3\", \"ADL_4\", \"ADL_5\", \"ADL_6\", \"NAD_0\", \"NAD_1\", \"NAD_2\", \"NAD_3\", \"NAD_4\", \"NAD_5\", \"NAD_6\", \"buzz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d49fc974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NCD_0</th>\n",
       "      <th>NCD_1</th>\n",
       "      <th>NCD_2</th>\n",
       "      <th>NCD_3</th>\n",
       "      <th>NCD_4</th>\n",
       "      <th>NCD_5</th>\n",
       "      <th>NCD_6</th>\n",
       "      <th>AI_0</th>\n",
       "      <th>AI_1</th>\n",
       "      <th>AI_2</th>\n",
       "      <th>...</th>\n",
       "      <th>ADL_5</th>\n",
       "      <th>ADL_6</th>\n",
       "      <th>NAD_0</th>\n",
       "      <th>NAD_1</th>\n",
       "      <th>NAD_2</th>\n",
       "      <th>NAD_3</th>\n",
       "      <th>NAD_4</th>\n",
       "      <th>NAD_5</th>\n",
       "      <th>NAD_6</th>\n",
       "      <th>buzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "      <td>140706.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>172.274729</td>\n",
       "      <td>155.145054</td>\n",
       "      <td>165.458829</td>\n",
       "      <td>176.816085</td>\n",
       "      <td>186.933308</td>\n",
       "      <td>216.202621</td>\n",
       "      <td>243.860276</td>\n",
       "      <td>87.046871</td>\n",
       "      <td>78.635438</td>\n",
       "      <td>84.266001</td>\n",
       "      <td>...</td>\n",
       "      <td>1.113444</td>\n",
       "      <td>1.196132</td>\n",
       "      <td>172.833717</td>\n",
       "      <td>155.625311</td>\n",
       "      <td>165.933031</td>\n",
       "      <td>177.310349</td>\n",
       "      <td>187.459405</td>\n",
       "      <td>216.769711</td>\n",
       "      <td>244.472965</td>\n",
       "      <td>0.197390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>509.870507</td>\n",
       "      <td>471.570282</td>\n",
       "      <td>495.357468</td>\n",
       "      <td>528.350500</td>\n",
       "      <td>560.330850</td>\n",
       "      <td>632.185796</td>\n",
       "      <td>707.400841</td>\n",
       "      <td>234.729351</td>\n",
       "      <td>218.444310</td>\n",
       "      <td>233.533494</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374292</td>\n",
       "      <td>1.826157</td>\n",
       "      <td>510.935798</td>\n",
       "      <td>472.459796</td>\n",
       "      <td>496.230805</td>\n",
       "      <td>529.285749</td>\n",
       "      <td>561.309068</td>\n",
       "      <td>633.201370</td>\n",
       "      <td>708.435459</td>\n",
       "      <td>0.398031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.119048</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24210.000000</td>\n",
       "      <td>22899.000000</td>\n",
       "      <td>20495.000000</td>\n",
       "      <td>27007.000000</td>\n",
       "      <td>30957.000000</td>\n",
       "      <td>28603.000000</td>\n",
       "      <td>37505.000000</td>\n",
       "      <td>15105.000000</td>\n",
       "      <td>15730.000000</td>\n",
       "      <td>16389.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>185.666672</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>24301.000000</td>\n",
       "      <td>22980.000000</td>\n",
       "      <td>20495.000000</td>\n",
       "      <td>27071.000000</td>\n",
       "      <td>31028.000000</td>\n",
       "      <td>28697.000000</td>\n",
       "      <td>37505.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               NCD_0          NCD_1          NCD_2          NCD_3  \\\n",
       "count  140706.000000  140706.000000  140706.000000  140706.000000   \n",
       "mean      172.274729     155.145054     165.458829     176.816085   \n",
       "std       509.870507     471.570282     495.357468     528.350500   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         3.000000       2.000000       3.000000       3.000000   \n",
       "50%        22.000000      19.000000      20.000000      22.000000   \n",
       "75%       125.000000     112.000000     119.000000     126.000000   \n",
       "max     24210.000000   22899.000000   20495.000000   27007.000000   \n",
       "\n",
       "               NCD_4          NCD_5          NCD_6           AI_0  \\\n",
       "count  140706.000000  140706.000000  140706.000000  140706.000000   \n",
       "mean      186.933308     216.202621     243.860276      87.046871   \n",
       "std       560.330850     632.185796     707.400841     234.729351   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         3.000000       4.000000       5.000000       2.000000   \n",
       "50%        23.000000      28.000000      33.000000      13.000000   \n",
       "75%       133.000000     161.000000     186.000000      70.000000   \n",
       "max     30957.000000   28603.000000   37505.000000   15105.000000   \n",
       "\n",
       "                AI_1           AI_2  ...          ADL_5          ADL_6  \\\n",
       "count  140706.000000  140706.000000  ...  140706.000000  140706.000000   \n",
       "mean       78.635438      84.266001  ...       1.113444       1.196132   \n",
       "std       218.444310     233.533494  ...       1.374292       1.826157   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         2.000000       2.000000  ...       1.000000       1.000000   \n",
       "50%        11.000000      13.000000  ...       1.000000       1.000000   \n",
       "75%        64.000000      67.000000  ...       1.100000       1.119048   \n",
       "max     15730.000000   16389.000000  ...     185.666672     295.000000   \n",
       "\n",
       "               NAD_0          NAD_1          NAD_2          NAD_3  \\\n",
       "count  140706.000000  140706.000000  140706.000000  140706.000000   \n",
       "mean      172.833717     155.625311     165.933031     177.310349   \n",
       "std       510.935798     472.459796     496.230805     529.285749   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         3.000000       2.000000       3.000000       3.000000   \n",
       "50%        22.000000      19.000000      21.000000      22.000000   \n",
       "75%       126.000000     113.000000     119.000000     127.000000   \n",
       "max     24301.000000   22980.000000   20495.000000   27071.000000   \n",
       "\n",
       "               NAD_4          NAD_5          NAD_6           buzz  \n",
       "count  140706.000000  140706.000000  140706.000000  140706.000000  \n",
       "mean      187.459405     216.769711     244.472965       0.197390  \n",
       "std       561.309068     633.201370     708.435459       0.398031  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         3.000000       4.000000       6.000000       0.000000  \n",
       "50%        23.000000      28.000000      33.000000       0.000000  \n",
       "75%       134.000000     162.000000     187.000000       0.000000  \n",
       "max     31028.000000   28697.000000   37505.000000       1.000000  \n",
       "\n",
       "[8 rows x 78 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Twitter_Absolute_Sigma.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c4f9829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140706 entries, 0 to 140705\n",
      "Data columns (total 78 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   NCD_0     140706 non-null  int64  \n",
      " 1   NCD_1     140706 non-null  int64  \n",
      " 2   NCD_2     140706 non-null  int64  \n",
      " 3   NCD_3     140706 non-null  int64  \n",
      " 4   NCD_4     140706 non-null  int64  \n",
      " 5   NCD_5     140706 non-null  int64  \n",
      " 6   NCD_6     140706 non-null  int64  \n",
      " 7   AI_0      140706 non-null  int64  \n",
      " 8   AI_1      140706 non-null  int64  \n",
      " 9   AI_2      140706 non-null  int64  \n",
      " 10  AI_3      140706 non-null  int64  \n",
      " 11  AI_4      140706 non-null  int64  \n",
      " 12  AI_5      140706 non-null  int64  \n",
      " 13  AI_6      140706 non-null  int64  \n",
      " 14  AS_NA_0   140706 non-null  float64\n",
      " 15  AS_NA_1   140706 non-null  float64\n",
      " 16  AS_NA_2   140706 non-null  float64\n",
      " 17  AS_NA_3   140706 non-null  float64\n",
      " 18  AS_NA_4   140706 non-null  float64\n",
      " 19  AS_NA_5   140706 non-null  float64\n",
      " 20  AS_NA_6   140706 non-null  float64\n",
      " 21  BL_0      140706 non-null  float64\n",
      " 22  BL_1      140706 non-null  float64\n",
      " 23  BL_2      140706 non-null  float64\n",
      " 24  BL_3      140706 non-null  float64\n",
      " 25  BL_4      140706 non-null  float64\n",
      " 26  BL_5      140706 non-null  float64\n",
      " 27  BL_6      140706 non-null  float64\n",
      " 28  NAC_0     140706 non-null  int64  \n",
      " 29  NAC_1     140706 non-null  int64  \n",
      " 30  NAC_2     140706 non-null  int64  \n",
      " 31  NAC_3     140706 non-null  int64  \n",
      " 32  NAC_4     140706 non-null  int64  \n",
      " 33  NAC_5     140706 non-null  int64  \n",
      " 34  NAC_6     140706 non-null  int64  \n",
      " 35  AS_NAC_0  140706 non-null  float64\n",
      " 36  AS_NAC_1  140706 non-null  float64\n",
      " 37  AS_NAC_2  140706 non-null  float64\n",
      " 38  AS_NAC_3  140706 non-null  float64\n",
      " 39  AS_NAC_4  140706 non-null  float64\n",
      " 40  AS_NAC_5  140706 non-null  float64\n",
      " 41  AS_NAC_6  140706 non-null  float64\n",
      " 42  CS_0      140706 non-null  float64\n",
      " 43  CS_1      140706 non-null  float64\n",
      " 44  CS_2      140706 non-null  float64\n",
      " 45  CS_3      140706 non-null  float64\n",
      " 46  CS_4      140706 non-null  float64\n",
      " 47  CS_5      140706 non-null  float64\n",
      " 48  CS_6      140706 non-null  float64\n",
      " 49  AT_0      140706 non-null  float64\n",
      " 50  AT_1      140706 non-null  float64\n",
      " 51  AT_2      140706 non-null  float64\n",
      " 52  AT_3      140706 non-null  float64\n",
      " 53  AT_4      140706 non-null  float64\n",
      " 54  AT_5      140706 non-null  float64\n",
      " 55  AT_6      140706 non-null  float64\n",
      " 56  NA_0      140706 non-null  int64  \n",
      " 57  NA_1      140706 non-null  int64  \n",
      " 58  NA_2      140706 non-null  int64  \n",
      " 59  NA_3      140706 non-null  int64  \n",
      " 60  NA_4      140706 non-null  int64  \n",
      " 61  NA_5      140706 non-null  int64  \n",
      " 62  NA_6      140706 non-null  int64  \n",
      " 63  ADL_0     140706 non-null  float64\n",
      " 64  ADL_1     140706 non-null  float64\n",
      " 65  ADL_2     140706 non-null  float64\n",
      " 66  ADL_3     140706 non-null  float64\n",
      " 67  ADL_4     140706 non-null  float64\n",
      " 68  ADL_5     140706 non-null  float64\n",
      " 69  ADL_6     140706 non-null  float64\n",
      " 70  NAD_0     140706 non-null  int64  \n",
      " 71  NAD_1     140706 non-null  int64  \n",
      " 72  NAD_2     140706 non-null  int64  \n",
      " 73  NAD_3     140706 non-null  int64  \n",
      " 74  NAD_4     140706 non-null  int64  \n",
      " 75  NAD_5     140706 non-null  int64  \n",
      " 76  NAD_6     140706 non-null  int64  \n",
      " 77  buzz      140706 non-null  float64\n",
      "dtypes: float64(43), int64(35)\n",
      "memory usage: 83.7 MB\n"
     ]
    }
   ],
   "source": [
    "Twitter_Absolute_Sigma.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49f2e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Twitter_Absolute_Sigma['buzz'] = Twitter_Absolute_Sigma['buzz'].map( {1.0: 1, 0.0: 0} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab15c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Twitter_Absolute_Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aaf9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X.drop(['buzz'],axis = 1)\n",
    "y = Twitter_Absolute_Sigma['buzz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18b3064b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19739030318536524"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()/y.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f943761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8026096968146348"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y.mean(), 1 - y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a856ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0184b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dummytrain,sample_data,Dummytrain2,sample_target = train_test_split(X, y, shuffle = True, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aa7df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_data\n",
    "y = sample_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5dadddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14071, 77)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9511b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1dbddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "001c4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)\n",
    "\n",
    "X_full_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0054ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29476c58",
   "metadata": {},
   "source": [
    "# Apply Four Voting Classifiers - Hard and Soft Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959b16eb",
   "metadata": {},
   "source": [
    "### Classifier 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c36498c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, max_iter=300, solver='newton-cg')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_classifier = LogisticRegression(solver='newton-cg',max_iter=300, C=100)\n",
    "logistic_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eb02b8",
   "metadata": {},
   "source": [
    "### Classifier 2 - KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e380cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier(30)\n",
    "knn_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840acf24",
   "metadata": {},
   "source": [
    "### Classifier 3 - Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c43087d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, max_iter=20000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_svc_classifier = LinearSVC(C=10, max_iter=20000)\n",
    "linear_svc_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246db854",
   "metadata": {},
   "source": [
    "### Classifier 4 - Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec32b8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree_classifier = DecisionTreeClassifier(max_depth=3)\n",
    "decision_tree_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42a7a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafcf212",
   "metadata": {},
   "source": [
    "## Voting Classifier with Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac1caa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9658897100625355\n",
      "KNeighborsClassifier 0.961910176236498\n",
      "LinearSVC 0.966173962478681\n",
      "DecisionTreeClassifier 0.9638999431495168\n",
      "VotingClassifier 0.9653212052302445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=[('logistic_classifier', logistic_classifier),('knn_classifier', knn_classifier),('decision_tree_classifier', decision_tree_classifier),('linear_svc_classifier',linear_svc_classifier)], voting='hard')\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for classifier in (logistic_classifier, knn_classifier, linear_svc_classifier, decision_tree_classifier, voting_classifier):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print(classifier.__class__.__name__, score)\n",
    "    classifier_scores[classifier.__class__.__name__+\" (Hard Voting)\"] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e66a5",
   "metadata": {},
   "source": [
    "## Voting Classifier with Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3750aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9658897100625355\n",
      "KNeighborsClassifier 0.961910176236498\n",
      "DecisionTreeClassifier 0.9638999431495168\n",
      "VotingClassifier 0.9656054576463899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=[('logistic_classifier', logistic_classifier),('knn_classifier', knn_classifier),('decision_tree_classifier', decision_tree_classifier)], voting='soft')\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for classifier in (logistic_classifier, knn_classifier, decision_tree_classifier, voting_classifier):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    score =  accuracy_score(y_test, y_pred)\n",
    "    print(classifier.__class__.__name__, score)\n",
    "    classifier_scores[classifier.__class__.__name__+\" (Soft Voting)\"] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c80180",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c161d7",
   "metadata": {},
   "source": [
    "## Determining the best value of the parameters in gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba8526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9641841955656623\n",
      "0.965036952814099\n",
      "0.9667424673109721\n",
      "0.9647527003979534\n",
      "0.966173962478681\n",
      "0.966173962478681\n",
      "0.9653212052302445\n",
      "0.9664582148948266\n",
      "0.9653212052302445\n",
      "0.9641841955656623\n",
      "0.9633314383172257\n",
      "0.9602046617396248\n",
      "0.9656054576463899\n",
      "0.9627629334849346\n",
      "0.9636156907333713\n",
      "0.9656054576463899\n",
      "0.9633314383172257\n",
      "0.9610574189880614\n",
      "0.9641841955656623\n",
      "0.9545196134167141\n",
      "0.9553723706651507\n",
      "0.9653212052302445\n",
      "0.9530983513359863\n"
     ]
    }
   ],
   "source": [
    "learning_rate_list = [0.1, 0.5, 1.0]\n",
    "n_estimators_list = [100, 200, 300]\n",
    "max_depth_list = [1, 2, 3]\n",
    "max_score = 0\n",
    "best_param = {}\n",
    "for learning_rate_val in learning_rate_list:\n",
    "    for n_estimators_val in n_estimators_list:\n",
    "        for max_depth_val in max_depth_list:\n",
    "            clf = GradientBoostingClassifier(n_estimators=n_estimators_val, learning_rate=learning_rate_val, max_depth=max_depth_val, random_state=0).fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            print(score)\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_param[\"learning_rate\"] = learning_rate_val\n",
    "                best_param[\"n_estimators\"] = n_estimators_val\n",
    "                best_param[\"max_depth\"] = max_depth_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best value for n_estimators \"+ str(best_param[\"n_estimators\"]))\n",
    "print(\"Best value for learning rate \"+ str(best_param[\"learning_rate\"]))\n",
    "print(\"Best value for max_depth \"+ str(best_param[\"max_depth\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b19e6c",
   "metadata": {},
   "source": [
    "## Based on the best parameters value determined above we fit the gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc5ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_clf = GradientBoostingClassifier(n_estimators=best_param[\"n_estimators\"], learning_rate=best_param[\"learning_rate\"], max_depth=best_param[\"max_depth\"], random_state=0).fit(X_train, y_train)\n",
    "score = gradient_boosting_clf.score(X_test, y_test)\n",
    "classifier_scores[\"Gradient Boosting\"] = score\n",
    "print(\"Prediction score when using gradient boosting classifier \"+ str(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3758e6",
   "metadata": {},
   "source": [
    "# Comparing the various classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scores = {k: v for k, v in sorted(classifier_scores.items(), key=lambda item: item[1])}\n",
    "sorted_scored = sorted_scores.items()\n",
    "x, y = sorted_scores.keys(), sorted_scores.values()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([1,1,1,1])\n",
    "ax.plot(x, y)\n",
    "plt.xlabel('Classifier')\n",
    "labels = [ '\\n'.join(wrap(name, 20)) for name in classifier_scores.keys()]\n",
    "ax.set_xticklabels(labels)\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Scores of Different Classifiers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7875dc34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
